{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "#from zipfile import ZipFile\n",
    "from urllib.request import urlretrieve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ETL process\n",
    "* download zip file\n",
    "* extract the zipped csv file\n",
    "* apply transformations to the csv file\n",
    "* load the new csv data into a postgresql database\n",
    "* generate insights for the shareholders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading a ZIP file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "url_path= 'https://assets.datacamp.com/production/repositories/5899/datasets/19d6cf619d6a771314f0eb489262a31f89c424c2/ppr-all.zip'\n",
    "\n",
    "# Get the zip file\n",
    "response = requests.get(url_path)\n",
    "\n",
    "# Print the status code\n",
    "print(response.status_code)\n",
    "\n",
    "# Save the file locally (more about open() in the next lesson)\n",
    "local_path = f\"./ppr-all.zip\"\n",
    "with open(local_path, \"wb\") as f:\n",
    "    f.write(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#another way to get the zip file from the url\n",
    "urlretrieve(url_path,'_ppr-all.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring a ZIP file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of files:  ['ppr-all.csv']\n",
      "Extract Path:  ppr-all.csv\n"
     ]
    }
   ],
   "source": [
    "# Import the required method\n",
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile(local_path, mode=\"r\") as f:\n",
    "  \t# Get the list of files and print it\n",
    "    file_names = f.namelist()\n",
    "    print(\"List of files: \", file_names)\n",
    "    # Extract the CSV file\n",
    "    csv_file_path = f.extract(file_names[0], path='./')\n",
    "    print(\"Extract Path: \" , csv_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading from a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'Address': '16 BURLEIGH COURT, BURLINGTON ROAD, DUBLIN 4',\n",
      " 'County': 'Dublin',\n",
      " 'Date of Sale (dd/mm/yyyy)': '03/01/2021',\n",
      " 'Description of Property': 'Second-Hand Dwelling house /Apartment',\n",
      " 'Postal Code': 'Dublin 4',\n",
      " 'Price (€)': '€450,000.00'}\n",
      "'16 BURLEIGH COURT, BURLINGTON ROAD, DUBLIN 4'\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from pprint import pprint\n",
    "\n",
    "path= './ppr-all.csv'\n",
    "\n",
    "# Open the csv file in read mode\n",
    "with open(path, mode=\"r\", encoding=\"windows-1252\") as csv_file:\n",
    "    # Open csv_file so that each row is a dictionary\n",
    "    reader = csv.DictReader(csv_file)\n",
    "    \n",
    "    # Print the first row\n",
    "    row = next(reader)\n",
    "    print(type(row))\n",
    "    pprint(row)\n",
    "    pprint(row['Address'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "new_column_names = {\n",
    "    \"Date of Sale (dd/mm/yyyy)\": \"date_of_sale\",\n",
    "    \"Address\": \"address\",\n",
    "    \"Postal Code\": \"postal_code\",\n",
    "    \"County\": \"county\",\n",
    "    \"Price (€)\": \"price\",\n",
    "    \"Description of Property\": \"description\",\n",
    "}\n",
    "\n",
    "with open(path, mode=\"r\", encoding=\"windows-1252\") as reader_csv_file:\n",
    "    reader = csv.DictReader(reader_csv_file)\n",
    "    \n",
    "\n",
    "    # The new file is called \"PPR-2021-Dublin-new-headers.csv\"\n",
    "    # and will be saved inside the \"tmp\" folder    \n",
    "    with open(\"./PPR-2021-Dublin-new-headers.csv\",\n",
    "                    mode=\"w\",\n",
    "                    encoding=\"windows-1252\",\n",
    "                ) as writer_csv_file:\n",
    "        writer = csv.DictWriter(writer_csv_file, fieldnames=new_column_names)\n",
    "        \n",
    "        # Write header as first line\n",
    "        writer.writerow(new_column_names) #could also use writer.writeheader()\n",
    "        for row in reader:\n",
    "\t        # Write all rows in file\n",
    "\t        writer.writerow(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['date_of_sale', 'address', 'postal_code', 'county', 'price', 'description'])\n"
     ]
    }
   ],
   "source": [
    "#now can see the result\n",
    "with open('./PPR-2021-Dublin-new-headers.csv', mode=\"r\", encoding=\"windows-1252\") as reader_csv_file :\n",
    "    reader = csv.DictReader(reader_csv_file)\n",
    "    pprint(list(reader)[0].keys())\n",
    "    #row = next(reader)\n",
    "    #pprint(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Engines and sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function needed\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import Session\n",
    "\n",
    "# Create the engine\n",
    "engine = create_engine(\"postgresql+psycopg2://dcstudent:S3cretPassw0rd@localhost:5432/campdata-prod\")\n",
    "\n",
    "# Create the session\n",
    "session = Session(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the submodule required\n",
    "from datetime import datetime\n",
    "\n",
    "def transform_case(input_string):\n",
    "    \"\"\"\n",
    "    Lowercase string fields\n",
    "    \"\"\"\n",
    "    # Return the string lowercase\n",
    "    return input_string.lower()\n",
    "  \n",
    "def update_date_of_sale(date_input):\n",
    "    \"\"\"\n",
    "    Update date format from DD/MM/YYYY to YYYY-MM-DD\n",
    "    \"\"\"\n",
    "    # Create a datetime object\n",
    "    current_format = datetime.strptime(date_input, \"%d/%m/%Y\")\n",
    "    # Convert to the expected date format\n",
    "    new_format = current_format.strftime(\"%Y-%m-%d\")\n",
    "    return new_format\n",
    "    \n",
    "\n",
    "def update_price(price_input):\n",
    "    \"\"\"\n",
    "    Returns price as an integer by removing:\n",
    "    - \"€\" and \",\" symbol\n",
    "    - Converting to float first then to integer\n",
    "    \"\"\"\n",
    "    # Replace € with an empty string\n",
    "    price_input = price_input.replace(\"€\", \"\")\n",
    "    # Replace comma with an empty string\n",
    "    price_input = price_input.replace(\",\", \"\")\n",
    "    # Convert to float\n",
    "    price_input = float(price_input)\n",
    "    # Return price_input as integer\n",
    "    return int(price_input)\n",
    "  \n",
    "def update_description(description_input):\n",
    "    \"\"\"\n",
    "    Simplifies the description field for future analysis. Returns:\n",
    "    - \"new\" if string contains \"new\" substring\n",
    "    - \"second-hand\" if string contains \"second-hand\" substring\n",
    "    \"\"\"\n",
    "    description_input = transform_case(description_input)\n",
    "    # Check description and return \"new\" or \"second-hand\"\n",
    "    if \"new\" in description_input:\n",
    "        return \"new\"\n",
    "    elif \"second-hand\" in description_input:\n",
    "        return \"second-hand\"\n",
    "    return description_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the session to get row with id equal to 2\n",
    "results = session.query(PprRawAll).filter(PprRawAll.id == 2)\n",
    "\n",
    "# Get the corresponding address\n",
    "print(\"Address:\", results[0].address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function required\n",
    "from sqlalchemy.dialects.postgresql import insert\n",
    "  \n",
    "values = [{\"date_of_sale\": \"2021-01-01\",\n",
    "           \"address\": \"14 bow street\",\n",
    "           \"postal_code\": \"dublin 7\",\n",
    "           \"county\": \"dublin\",\n",
    "           \"price\": 350000,\n",
    "           \"description\":\"second-hand\"}]\n",
    "\n",
    "# Insert values in PprCleanAll\n",
    "stmt = insert(PprCleanAll).values(values)\n",
    "\n",
    "# Execute and commit\n",
    "session.execute(stmt)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function required\n",
    "from sqlalchemy import delete\n",
    "\n",
    "# Delete rows lacking a description value\n",
    "stmt = delete(PprCleanAll).filter(PprCleanAll.description==\"\")\n",
    "#Could also delete filtered rows at the end of a query ie.\n",
    "#session.query(Movies).filter(Movies.title== \"movie title\").delete()\n",
    "\n",
    "# Execute and commit\n",
    "session.execute(stmt)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import cast\n",
    "from sqlalchemy.dialects.postgresql import insert\n",
    "\n",
    "# Select the transaction ids\n",
    "clean_transaction_ids = session.query(PprCleanAll.transaction_id)\n",
    "\n",
    "# Select the columns and cast the appropriate types if needed\n",
    "transactions_to_insert = session.query(\n",
    "    cast(PprRawAll.date_of_sale, Date),\n",
    "    PprRawAll.address,\n",
    "    PprRawAll.postal_code,\n",
    "    PprRawAll.county,\n",
    "    cast(PprRawAll.price, Integer),\n",
    "    PprRawAll.description,\n",
    "  # Filter for the new rows\n",
    ").filter(~PprRawAll.transaction_id.in_(clean_transaction_ids))\n",
    "\n",
    "# Print total number of transactions to insert\n",
    "# it should be 3154 if the transactions need to be inserted\n",
    "# 0, if all transactions have been inserted\n",
    "print(\"Transactions to insert:\", transactions_to_insert.count())\n",
    "\n",
    "# Insert the rows from the previously selected transactions\n",
    "columns = [\"date_of_sale\", \"address\", \"postal_code\",\n",
    "          \"county\", \"price\",\"description\"]\n",
    "stm = insert(PprCleanAll).from_select(columns, transactions_to_insert)\n",
    "\n",
    "# Execute and commit the statement to make changes in the database.\n",
    "session.execute(stm)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the delete module\n",
    "from sqlalchemy import delete\n",
    "\n",
    "# Get all the ppr_raw_all transaction ids\n",
    "raw_transaction_ids = session.query(PprRawAll.transaction_id)\n",
    "\n",
    "# Filter all the ppr_clean_all table transactions that are not present in the ppr_raw_all table\n",
    "transactions_to_delete = session.query(PprCleanAll).filter(~PprCleanAll.transaction_id.in_(raw_transaction_ids))\n",
    "\n",
    "# Print transactions to delete\n",
    "print(\"Transactions to delete:\", transactions_to_delete.count())\n",
    "\n",
    "# Delete the selected transactions\n",
    "# (Please note: the param \"synchronize_session=False\" has been inserted\n",
    "# to avoid inconsistent results if a session expires)\n",
    "transactions_to_delete.delete(synchronize_session=False)\n",
    "\n",
    "# Commit the session to make the changes in the database\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "operators and queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* in / not in:  in_, ~in_\n",
    "* basic comparison: ==, !=, >, >= , <, <=\n",
    "* identity: is_, is_not\n",
    "* string_comparison: like notlike\n",
    "* conjuctions and negations: and_, or_ \n",
    "\n",
    "Use:\n",
    "* and_(expression1, expression2, ..., expressionN)\n",
    "* (expression1 & expression2 & ... & expressionN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the operator you need\n",
    "from sqlalchemy import or_\n",
    "\n",
    "# Query the clean table to retrieve the total number of\n",
    "# transactions for the Dublin or Cork counties\n",
    "result = session.query(PprCleanAll) \\\n",
    "                .filter(or_(PprCleanAll.county == \"dublin\", PprCleanAll.county == \"cork\")) \\\n",
    "                .all()\n",
    "\n",
    "print(\"First row address:\", result[0].address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the and function needed\n",
    "from sqlalchemy import and_\n",
    "\n",
    "# Retrieve all sales transactions for January 2021\n",
    "result = session.query(PprCleanAll).filter(and_(PprCleanAll.date_of_sale >= \"2021-01-01\", PprCleanAll.date_of_sale <= \"2021-01-31\")).all()\n",
    "\n",
    "print(\"First row address:\", result[0].address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aggregate functions and group by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the submodule required\n",
    "from sqlalchemy import func\n",
    "\n",
    "# Get the maximum, minimum and average values for each product category\n",
    "result = session.query(Products.category,\n",
    "                       func.max(Products.price),\n",
    "                       func.min(Products.price),\n",
    "                       func.avg(Products.price)) \\\n",
    "                .group_by(Products.category).all()\n",
    "\n",
    "print(\"Result:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the insights view and writing pure sql queries with python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.base import session\n",
    "\n",
    "# Create the view with the appropriate metrics\n",
    "query = \"\"\"\n",
    "create or replace view insights AS\n",
    "SELECT county,\n",
    "       count(*) AS sales_count,\n",
    "       sum(CAST(price AS int)) AS sales_total,\n",
    "       max(CAST(price AS int)) AS sales_max,\n",
    "       min(CAST(price AS int)) AS sales_min,\n",
    "       avg(CAST(price AS int))::numeric(10,2) AS sales_avg\n",
    "FROM ppr_clean_all\n",
    "GROUP BY county\n",
    "\"\"\"\n",
    "\n",
    "# Execute and commit\n",
    "session.execute(query) #it is possible to execute raw SQL as an argument for session.execute()\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.execute(\"SELECT COUNT(*) FROM insights\").all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with excel files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "\n",
    "workbook = xlsxwriter.Workbook(\"Greetings.xlsx\")\n",
    "worksheet = workbook.add_worksheet()\n",
    "worksheet.write(0, 0,\n",
    "\"Hello Datacamp\")\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "workbook = xlsxwriter.Workbook(\"Books.xlsx\")\n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "data = [[1,\"Sapiens\"],\n",
    "        [2,\"Greenlights\"]]\n",
    "\n",
    "worksheet.add_table(\n",
    "    \"B3:E6\",{\"data\": data,\n",
    "    \"columns\": [\n",
    "    {\"header\": \"id\"},\n",
    "    {\"header\": \"name\"}\n",
    "    ]})\n",
    "\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example adding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the library needed\n",
    "import xlsxwriter\n",
    "\n",
    "# Create a new Excel file\n",
    "workbook = xlsxwriter.Workbook(\"insights.xlsx\")\n",
    "\n",
    "# Initialize a worksheet\n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "# Write the data in the current sheet\n",
    "data = [\"Hello\", \"Datacamp\"]\n",
    "worksheet.write(0, 0, data[0])\n",
    "worksheet.write(0, 1, data[1])\n",
    "\n",
    "# Close the file\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example adding tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "\n",
    "workbook = xlsxwriter.Workbook(\"Products.xlsx\")\n",
    "worksheet = workbook.add_worksheet()\n",
    "    \n",
    "# Create a table with the available data in the current sheet\n",
    "worksheet.add_table(\n",
    "    \"B3:E8\",\n",
    "    {\n",
    "        \"data\": data,\n",
    "        \"columns\": [\n",
    "          \t# Use the appropriate names for the columns\n",
    "            {\"header\": \"id\"},\n",
    "            {\"header\": \"category\"},\n",
    "            {\"header\": \"name\"},\n",
    "            {\"header\": \"price\"},\n",
    "        ],\n",
    "    },\n",
    ")\n",
    "\n",
    "# Close the current file\n",
    "workbook.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7667d99e2bf14517c98008973f89041f63666917455533e893f8527c66c786f6"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
